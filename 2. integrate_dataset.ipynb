{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from process_text import text_to_words, text_to_vectors\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read admissions\n",
    "admissions = pd.read_csv(\"data/source/admissions.csv\", \n",
    "                         sep=\";\",\n",
    "                         parse_dates=['start_datetime', 'end_datetime']\n",
    "                        )\n",
    "\n",
    "# Read incidents\n",
    "incidents = pd.read_csv(\"data/source/incidents.csv\", \n",
    "                        sep=\";\",\n",
    "                        parse_dates=['datetime']\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read notes\n",
    "notes = pd.read_csv(\"data/source/notes.csv\", \n",
    "                    sep=\";\", \n",
    "                    parse_dates=['datetime']\n",
    "                   )\n",
    "\n",
    "# Read trained paragraph2vec model\n",
    "paragraph2vec_model = Doc2Vec.load('models/paragraph2vec_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Process incidents\n",
    "We integrate incidents with admissions, based on a definition of a positive outcome: at least one violence incident after 24 hours of admission, and up to the first 28 days of admission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join admissions and incidents\n",
    "adm_incidents = admissions[['patient_id', 'start_datetime', 'admission_id']].merge(\n",
    "    incidents[['patient_id', 'datetime', 'incident_id']], how='inner')\n",
    "\n",
    "# Determine how much time between start of admission and each incident\n",
    "adm_incidents['day_diff'] = (adm_incidents['datetime'] - adm_incidents['start_datetime']) \n",
    "adm_incidents['day_diff'] = adm_incidents['day_diff'] / pd.Timedelta(\"24 hour\")\n",
    "\n",
    "# Only retain incidents after the first 24 hours, and up to the first 28 days of admission\n",
    "adm_incidents = adm_incidents[(adm_incidents['day_diff'] >= 1) & (adm_incidents['day_diff'] <= 28)]\n",
    "\n",
    "# Group incidents for each admission, by simply taking the first if multiple are present\n",
    "adm_incidents = adm_incidents.groupby(\"admission_id\").first()\n",
    "adm_incidents = adm_incidents.drop_duplicates()\n",
    "adm_incidents = adm_incidents.reset_index()\n",
    "\n",
    "# Merge this dataframe back to the original \n",
    "admissions = admissions.merge(adm_incidents[['admission_id', 'day_diff', 'incident_id']], how='left')\n",
    "\n",
    "# Determine outcome (i.e. the day_diff variable is not empty)\n",
    "admissions['outcome'] = admissions['day_diff'].notnull()\n",
    "admissions['outcome'] = admissions['outcome'].map({False : 0, True : 1})\n",
    "\n",
    "admissions['incident_id'] = admissions['incident_id'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Process notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select a relevant subset of notes, we integrate with admissions based on its start date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join admission info\n",
    "notes = notes.merge(\n",
    "    admissions[['patient_id', 'admission_id', 'start_datetime', 'transfer', 'outcome', 'incident_id']],\n",
    "    how='inner',\n",
    "    left_on='patient_id', \n",
    "    right_on='patient_id'\n",
    ")\n",
    "\n",
    "# Determine how much time between start of admission and each note\n",
    "notes['day_diff'] = (notes['start_datetime'] - notes['datetime']) \n",
    "notes['day_diff'] = notes['day_diff'] / pd.Timedelta(\"24 hour\")\n",
    "\n",
    "# Determine a threshold for inclusion of retrospective notes (i.e. one week or four weeks)\n",
    "notes['threshold'] = notes['transfer'].apply(lambda x : 7 if x else 28)\n",
    "\n",
    "# Retain notes that are after the threshold, and before 24 hours have passed\n",
    "notes = notes[(notes['day_diff'] <= notes['threshold'])]\n",
    "notes = notes[(notes['day_diff'] > -1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each admission, if multiple notes are present, they are concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concatenate multiple notes into a single text, add a newline character in between\n",
    "notes_concat = notes.groupby(\"admission_id\")['text'].agg(lambda x : \"\\n\".join(x)).reset_index() # add\n",
    "\n",
    "# Omit notes with fewer than 100 words\n",
    "notes_concat['no_words'] = notes_concat['text'].apply(lambda x : len(x.split(\" \"))) \n",
    "notes_concat = notes_concat[notes_concat['no_words'] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that there is only one gender per admission, so that we can keep it in the final file\n",
    "for adm_id in notes_concat.admission_id.to_list():\n",
    "    genders = set(notes[notes['admission_id'] == adm_id].Geslacht.to_list())\n",
    "    if len(genders) != 1:\n",
    "        raise Exception(adm_id, genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the number of words matches the input text\n",
    "if 'aantal_woorden_x' in notes.columns:\n",
    "    notes = notes.rename(columns = {'aantal_woorden_x': 'aantal_woorden'})\n",
    "n_word_len_mismatch = len(notes[notes['text'].apply(lambda x: len(x.split(' '))) != notes['aantal_woorden']])\n",
    "if n_word_len_mismatch != 0:\n",
    "    raise Exception(n_word_len_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender(dataframe):\n",
    "    gender = dataframe.groupby('admission_id')['Geslacht'].agg(lambda x: x.to_list()[0])\n",
    "    return gender\n",
    "\n",
    "def merge_series_with_aggreggated_notes(agg, a_series):\n",
    "    return agg.merge(a_series, on = 'admission_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that these functions do what they are supposed to\n",
    "test_df = pd.DataFrame()\n",
    "test_df['Geslacht'] = ['Man', 'Vrouw', 'Vrouw', 'Man', 'Man']\n",
    "test_df['admission_id'] = [1, 1, 7, 11, 11]\n",
    "genders = get_gender(test_df)\n",
    "if len(genders) != 3 or genders[1] != 'Man' or genders[7] != 'Vrouw' or genders[11] != 'Man':\n",
    "    raise Exception('get_gender does not do what it is supposed to do')\n",
    "agg = pd.DataFrame()\n",
    "agg['admission_id'] = [1, 7, 13]\n",
    "merged = merge_series_with_aggreggated_notes(agg, genders)\n",
    "\n",
    "def get_gender_agg(adm_id):\n",
    "    the_genders = merged[merged['admission_id'] == adm_id].Geslacht.to_list()\n",
    "    if len(the_genders) != 1:\n",
    "        raise Exception('Too many genders')\n",
    "    return the_genders[0]\n",
    "\n",
    "if len(merged) != 3 or get_gender_agg(1) != 'Man' or get_gender_agg(7) != 'Vrouw' or get_gender_agg(13) == get_gender_agg(13):\n",
    "    raise Exception(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_notes_by_adm = merge_series_with_aggreggated_notes(notes_concat, get_gender(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(set(agg_notes_by_adm.Geslacht.to_list())) != 2:\n",
    "    raise Exception('Incorrect genders')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to also add the datetime of the first and last notes, for each admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_and_max(a_list):\n",
    "    if len(a_list) == 0:\n",
    "        raise Exception('Cannot get min or max in empty list')\n",
    "    if len(a_list) == 1:\n",
    "        return (a_list[0], a_list[0])\n",
    "    the_min = a_list[0]\n",
    "    the_max = a_list[0]\n",
    "    for el in a_list[1:]:\n",
    "        if el > the_max:\n",
    "            the_max = el\n",
    "        if el < the_min:\n",
    "            the_min = el\n",
    "    return (the_min, the_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_passed = get_min_and_max([3]) == (3, 3)\n",
    "two_passed = get_min_and_max([3, 2]) == (2, 3)\n",
    "three_passed = get_min_and_max([3, 1, 2]) == (1, 3)\n",
    "if not single_passed or not two_passed or not three_passed:\n",
    "    raise Exception('Wrong min or max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_note_datetimes(dataframe):\n",
    "    datetimes = dataframe.groupby('admission_id')['datetime'].agg(lambda x: get_min_and_max(x.to_list()))\n",
    "    return datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that this functions does what it is supposed to\n",
    "test_df = pd.DataFrame()\n",
    "timestamps = ['2020-04-01 12:59', '2020-03-19 13:00', '2020-02-13 11:00', '2020-04-01 11:00', '2020-04-02 11:00', '2020-03-30 11:00']\n",
    "test_df['datetime'] = [pd.Timestamp(el) for el in timestamps]\n",
    "test_df['admission_id'] = [1, 1, 7, 11, 11, 11]\n",
    "note_datetimes = get_note_datetimes(test_df)\n",
    "passed_len = len(note_datetimes) == 3\n",
    "def tuple_matches_expected(admission_id, left, right):\n",
    "    the_tuple = note_datetimes[admission_id]\n",
    "    return the_tuple[0].day == left and the_tuple[1].day == right\n",
    "passed_1 = tuple_matches_expected(1, 19, 1)\n",
    "passed_2 = tuple_matches_expected(7, 13, 13)\n",
    "passed_3 = tuple_matches_expected(11, 30, 2)\n",
    "if not passed_len or not passed_1 or not passed_2 or not passed_3:\n",
    "    raise Exception(passed_len, passed_1, passed_2, passed_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = get_note_datetimes(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_datetimes = merge_series_with_aggreggated_notes(agg_notes_by_adm, datetimes)\n",
    "with_datetimes['first_note_datetime'] = with_datetimes['datetime'].apply(lambda x: x[0])\n",
    "with_datetimes['last_note_datetime'] = with_datetimes['datetime'].apply(lambda x: x[1])\n",
    "with_datetimes = with_datetimes.drop(['datetime'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_datetimes.to_csv('data/processed/notes_without_vectors.csv', sep = ';', index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a vector representation, by first converting text into words (with additional stemming), and then using a paragraph2vec model to obtain vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_concat = with_datetimes\n",
    "\n",
    "# Convert text to words\n",
    "notes_concat['words_stemmed'] = notes_concat['text'].apply(lambda x : text_to_words(x, \n",
    "                                                                                    filter_stopwords=True,\n",
    "                                                                                    stemming=True,\n",
    "                                                                                    filter_periods=True\n",
    "                                                                                    ))\n",
    "\n",
    "# Join with whitespace\n",
    "notes_concat['words_stemmed'] = notes_concat['words_stemmed'].apply(lambda x : ' '.join(x))\n",
    "\n",
    "notes_concat = notes_concat.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to vectors\n",
    "note_vectors = text_to_vectors(notes_concat, 'words_stemmed', paragraph2vec_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate to original dataframe\n",
    "notes_concat = pd.concat([notes_concat, pd.DataFrame(note_vectors)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally merge the patient_id and outcome from the `admission` table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge outcome from admission table\n",
    "notes_concat = notes_concat.merge(admissions[['outcome', 'admission_id', 'patient_id']])\n",
    "\n",
    "# Write processed data to file for other notebooks\n",
    "notes_concat.to_csv(\"data/processed/notes.csv\", \n",
    "                    sep=\";\", \n",
    "                    index=False, \n",
    "                    quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Descriptive statistics of dataset\n",
    "Now that source files have been integrated, we can print some descriptive statistics of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute length of stay (days)\n",
    "admissions['length'] = (admissions['end_datetime'].dt.date - admissions['start_datetime'].dt.date) \n",
    "admissions['length'] = admissions['length'] / pd.Timedelta(\"1 day\")\n",
    "\n",
    "print(\"Number of admissions = {}\".format(len(admissions)))\n",
    "print(\"Number of unique patients = {}\".format(admissions['patient_id'].nunique()))\n",
    "print(\"Median length of admission = {}\".format(admissions['length'].median()))\n",
    "print(\"Admissions with positive outcome = {:.2f}%\".format(100 * admissions['outcome'].mean()))\n",
    "print(\"Median number of words in notes = {}\".format(notes_concat['no_words'].median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute some additional statistics for incidents by integrating them with admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adminc = admissions.merge(incidents, left_on='patient_id', right_on='patient_id')\n",
    "adminc = adminc[(adminc['start_datetime'] <= adminc['datetime']) & (adminc['end_datetime'] >= adminc['datetime'])]\n",
    "adminc['days_after_admission'] = (adminc['datetime'] - adminc['start_datetime']) / pd.Timedelta('1 day')\n",
    "\n",
    "print(\"Number of incidents during admission = {} \".format(len(adminc)))\n",
    "print(\"Number of incidents within 28 days = {}\".format(sum(adminc['days_after_admission'] <= 28)))\n",
    "print(\"Number of incidents within 24 hours = {}\".format(sum(adminc['days_after_admission'] <= 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of incidents within 1 week = {}\".format(sum(adminc['days_after_admission'] <= 7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe because these numbers are small, Vincent carried on with a 28-day cut. I think what Marco is suggesting is that now that we can remove the cut on the end date of the data, we might find more incidents and therefore a bigger training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
