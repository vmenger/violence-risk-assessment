{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from process_text import text_to_words, text_to_vectors\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read admissions\n",
    "admissions = pd.read_csv(\"data/source/admissions.csv\", \n",
    "                         sep=\";\",\n",
    "                         parse_dates=['start_datetime', 'end_datetime']\n",
    "                        )\n",
    "\n",
    "# Read incidents\n",
    "incidents = pd.read_csv(\"data/source/incidents.csv\", \n",
    "                        sep=\";\",\n",
    "                        parse_dates=['datetime']\n",
    "                       )\n",
    "\n",
    "# Read notes\n",
    "notes = pd.read_csv(\"data/source/notes.csv\", \n",
    "                    sep=\";\", \n",
    "                    parse_dates=['datetime']\n",
    "                   )\n",
    "\n",
    "# Read trained paragraph2vec model\n",
    "paragraph2vec_model = Doc2Vec.load('models/paragraph2vec_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Process incidents\n",
    "We integrate incidents with admissions, based on a definition of a positive outcome: at least one violence incident after 24 hours of admission, and up to the first 28 days of admission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join admissions and incidents\n",
    "adm_incidents = admissions[['patient_id', 'start_datetime', 'admission_id']].merge(\n",
    "    incidents[['patient_id', 'datetime']], how='inner')\n",
    "\n",
    "# Determine how much time between start of admission and each incident\n",
    "adm_incidents['day_diff'] = (adm_incidents['datetime'] - adm_incidents['start_datetime']) \n",
    "adm_incidents['day_diff'] = adm_incidents['day_diff'] / pd.Timedelta(\"24 hour\")\n",
    "\n",
    "# Only retain incidents after the first 24 hours, and up to the first 28 days of admission\n",
    "adm_incidents = adm_incidents[(adm_incidents['day_diff'] >= 1) & (adm_incidents['day_diff'] <= 28)]\n",
    "\n",
    "# Group incidents for each admission, by simply taking the first if multiple are present\n",
    "adm_incidents = adm_incidents.groupby(\"admission_id\").first()\n",
    "adm_incidents = adm_incidents.drop_duplicates()\n",
    "adm_incidents = adm_incidents.reset_index()\n",
    "\n",
    "# Merge this dataframe back to the original \n",
    "admissions = admissions.merge(adm_incidents[['admission_id', 'day_diff']], how='left')\n",
    "\n",
    "# Determine outcome (i.e. the day_diff variable is not empty)\n",
    "admissions['outcome'] = admissions['day_diff'].notnull()\n",
    "admissions['outcome'] = admissions['outcome'].map({False : 0, True : 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Process notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select a relevant subset of notes, we integrate with admissions based on its start date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join admission info\n",
    "notes = notes.merge(\n",
    "    admissions[['patient_id', 'admission_id', 'start_datetime', 'transfer', 'outcome']],\n",
    "    how='inner',\n",
    "    left_on='patient_id', \n",
    "    right_on='patient_id'\n",
    ")\n",
    "\n",
    "# Determine how much time between start of admission and each note\n",
    "notes['day_diff'] = (notes['start_datetime'] - notes['datetime']) \n",
    "notes['day_diff'] = notes['day_diff'] / pd.Timedelta(\"24 hour\")\n",
    "\n",
    "# Determine a threshold for inclusion of retrospective notes (i.e. one week of four weeks)\n",
    "notes['threshold'] = notes['transfer'].apply(lambda x : 7 if x else 28)\n",
    "\n",
    "# Retain notes that are after the threshold, and before 24 hours have passed\n",
    "notes = notes[(notes['day_diff'] <= notes['threshold'])]\n",
    "notes = notes[(notes['day_diff'] > -1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each admission, if multiple notes are present, they are concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concatenate multiple notes into a single text, add a newline character in between\n",
    "notes_concat = notes.groupby(\"admission_id\")['text'].agg(lambda x : \"\\n\".join(x)).reset_index() # add\n",
    "\n",
    "# Omit notes with fewer than 100 words\n",
    "notes_concat['no_words'] = notes_concat['text'].apply(lambda x : len(x.split(\" \"))) \n",
    "notes_concat = notes_concat[notes_concat['no_words'] > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a vector representation, by first converting text into words (with additional stemming), and then using a paragraph2vec model to obtain vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to words\n",
    "notes_concat['words_stemmed'] = notes_concat['text'].apply(lambda x : text_to_words(x, \n",
    "                                                                                    filter_stopwords=True,\n",
    "                                                                                    stemming=True,\n",
    "                                                                                    filter_periods=True\n",
    "                                                                                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with whitespace\n",
    "notes_concat['words_stemmed'] = notes_concat['words_stemmed'].apply(lambda x : ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_concat = notes_concat.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to notes\n",
    "note_vectors = text_to_vectors(notes_concat, 'words_stemmed', paragraph2vec_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate to original dataframe\n",
    "notes_concat = pd.concat([notes_concat, pd.DataFrame(note_vectors)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally merge the patient_id and outcome from the `admission` table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge outcome from admission table\n",
    "notes_concat = notes_concat.merge(admissions[['outcome', 'admission_id', 'patient_id']])\n",
    "\n",
    "# Write processed data to file for other notebooks\n",
    "notes_concat.to_csv(\"data/processed/notes.csv\", \n",
    "                    sep=\";\", \n",
    "                    index=False, \n",
    "                    quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Descriptive statistics of dataset\n",
    "Now that source files have been integrated, we can print some descriptive statistics of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute length of stay (days)\n",
    "admissions['length'] = (admissions['end_datetime'].dt.date - admissions['start_datetime'].dt.date) \n",
    "admissions['length'] = admissions['length'] / pd.Timedelta(\"1 day\")\n",
    "\n",
    "print(\"Number of admissions = {}\".format(len(admissions)))\n",
    "print(\"Number of unique patients = {}\".format(admissions['patient_id'].nunique()))\n",
    "print(\"Median length of admission = {}\".format(admissions['length'].median()))\n",
    "print(\"Admissions with positive outcome = {:.2f}%\".format(100 * admissions['outcome'].mean()))\n",
    "print(\"Median number of words in notes = {}\".format(notes_concat['no_words'].median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute some additional statistics for incidents by integrating them with admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adminc = admissions.merge(incidents, left_on='patient_id', right_on='patient_id')\n",
    "adminc = adminc[(adminc['start_datetime'] <= adminc['datetime']) & (adminc['end_datetime'] >= adminc['datetime'])]\n",
    "adminc['days_after_admission'] = (adminc['datetime'] - adminc['start_datetime']) / pd.Timedelta('1 day')\n",
    "\n",
    "print(\"Number of incidents during admission = {} \".format(len(adminc)))\n",
    "print(\"Number of incidents within 28 days = {}\".format(sum(adminc['days_after_admission'] <= 28)))\n",
    "print(\"Number of incidents within 24 hours = {}\".format(sum(adminc['days_after_admission'] <= 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
